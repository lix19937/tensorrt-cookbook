# tensorrt-cookbook
deep insight tensorrt and oss  

对于深度学习推理，有五个用于衡量软件的关键因素：

* 吞吐量： 给定时间段内的产出量。 每台服务器的吞吐量通常以推断/秒或样本/秒来衡量，对于数据中心的经济高效扩展至关重要。   
* 效率：每单位功率交付的吞吐量，通常表示为性能/瓦特。效率是经济高效地扩展数据中心的另一个关键因素，因为服务器，服务器机架和整个数据中心必须在固定的功率预算内运行。   
* 延迟：执行推理的时间，通常以毫秒为单位。低延迟对于提供快速增长的基于实时推理的服务至关重要。    
* 准确性：训练好的神经网络能够提供正确答案。 对于图像分类算法，关键指标为top-5或top-1。 
* 内存使用情况：需要保留以在网络上进行推理的主机和设备内存取大小决于所使用的算法。这限制了哪些网络以及网络的哪些组合可以在给定的推理平台上运行。这对于需要多个网络且内存资源有限的系统尤其重要，例如，在智能视频分析和多摄像机，多网络自动驾驶系统中使用的级联多级检测网络。    

TensorRT的解决方案是：    
* 权重与激活精度校准：通过将模型量化为 FP16或INT8来更大限度地提高吞吐量，同时保持高准确度。   
* 层与张量融合 ：通过融合内核中的节点，优化GPU 显存和带宽的使用。   
* 内核自动调整：基于目标 GPU 平台选择最佳数据层和算法。   
* 动态张量显存：更大限度减少显存占用，并高效地为张量重复利用内存。   
* 多流执行：用于并行处理多个输入流的可扩展设计。    

