# tensorrt-cookbook
deep insight tensorrt and oss  

对于深度学习推理，有五个用于衡量软件的关键因素：

* 吞吐量： 给定时间段内的产出量。 每台服务器的吞吐量通常以推断/秒或样本/秒来衡量，对于数据中心的经济高效扩展至关重要。   
* 效率：每单位功率交付的吞吐量，通常表示为性能/瓦特。效率是经济高效地扩展数据中心的另一个关键因素，因为服务器，服务器机架和整个数据中心必须在固定的功率预算内运行。   
* 延迟：执行推理的时间，通常以毫秒为单位。低延迟对于提供快速增长的基于实时推理的服务至关重要。    
* 准确性：训练好的神经网络能够提供正确答案。 对于图像分类算法，关键指标为top-5或top-1。 
* 内存使用情况：需要保留以在网络上进行推理的主机和设备内存取大小决于所使用的算法。这限制了哪些网络以及网络的哪些组合可以在给定的推理平台上运行。这对于需要多个网络且内存资源有限的系统尤其重要，例如，在智能视频分析和多摄像机，多网络自动驾驶系统中使用的级联多级检测网络。    

TensorRT的解决方案是：    
* 权重与激活精度校准：通过将模型量化为 FP16或INT8来更大限度地提高吞吐量，同时保持高准确度。   
* 层与张量融合：通过融合内核中的节点，优化GPU 显存和带宽的使用。   
* 内核自动调整：基于目标 GPU 平台选择最佳数据层和算法。   
* 动态张量显存：更大限度减少显存占用，并高效地为张量重复利用内存。   
* 多流执行：用于并行处理多个输入流的可扩展设计。    

TensorRT对计算图主要执行以下优化：

* 消除输出不被使用的层。
* 消除等同于无操作的操作。
* 卷积，偏置和ReLU操作的融合。
* 汇总具有足够相似的参数和相同的源张量的操作（例如，GoogleNet v5的初始模块中的1x1卷积）。
* 通过将层输出定向到正确的最终目的地来合并串联图层（例如，消除concat）。
* 在构建阶段会在虚拟数据上运行各层，以从其核目录中选择最快的核，并在适当的情况下执行权重预格式化和内存优化。

以一个典型的inception block为例，优化过程如下：    
首先对网络结构进行垂直整合，即将目前主流神经网络的conv、BN、Relu三个层融合为了一个层，称之为CBR。    
然后对网络结构进行水平组合，水平组合是指将输入为相同张量和执行相同操作的层融合一起。inception block中将三个相连的1×1的CBR组合为一个大的1×1的CBR。   
最后处理concat层，将contact层的输入直接送入下面的操作中，不用单独进行concat后在输入计算，相当于减少了一次传输吞吐。 
